{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fa62f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819cd8d1",
   "metadata": {},
   "source": [
    "# 1. Welcome to the course!\n",
    "Welcome to the first course on Importing Data in Python! My name is Hugo Bowne-Anderson and I am a Data Scientist at DataCamp.\n",
    "\n",
    "2. Import data\n",
    "In this course, you'll learn how to import data from a large variety of import data sources, for example, (i) flat files such as dot txts and dot csvs; (ii) files native to other software such as Excel spreadsheets, Stata, SAS and MATLAB files;\n",
    "\n",
    "3. Import data\n",
    "(iii) relational databases such as SQLite & PostgreSQL. We’ll cover all of these topics in this course.\n",
    "\n",
    "4. Plain text files\n",
    "First off, we're going to learn how to import basic text files, which we can broadly classify into 2 types of files - those containing plain text, such as the opening of Mark Twain's novel The Adventures of Huckleberry Finn, which you can see here,\n",
    "\n",
    "5. Table data\n",
    "and those containing records, that is, table data, such as titanic dot csv, in which each\n",
    "\n",
    "1 Source: Kaggle\n",
    "6. Table data\n",
    "row is a unique passenger onboard and each\n",
    "\n",
    "7. Table data\n",
    "column is a characteristic or feature, such as gender, cabin and 'survived or not'. The latter is known as a flat file and we'll come back to these in a minute.\n",
    "\n",
    "8. Reading a text file\n",
    "In this section, we'll figure out how to read lines from a plain text file: So let's do it! To check out any plain text file, you can use Python’s basic open function to open a connection to the file. To do so, you assign the filename to a variable as a string, pass the filename to the function open and also pass it the argument mode equals 'r', which makes sure that we can only read it (we wouldn't want to accidentally write to it!), assign the text from the file to a variable text by applying the method read to the connection to the file. After you do this, make sure that you close the connection to the file using the command file dot close. It’s always best practice to clean while cooking!\n",
    "\n",
    "9. Printing a text file\n",
    "You can then print the file to console and check it out using the command print(text). A brief side note:\n",
    "\n",
    "10. Writing to a file\n",
    "if you wanted to open a file in order to write to it, you would pass it the argument mode equals 'w'. We won't use that in this course as this is course on Importing Data but it is good to know. You can avoid having to close the connection to the file by\n",
    "\n",
    "11. Context manager with\n",
    "using a with statement. This allows you to create a context in which you can execute commands with the file open. Once out of this clause/context, the file is no longer open and, for this reason, with is called a Context Manager. What you're doing here is called 'binding' a variable in the context manager construct; while still within this construct, the variable file will be bound to open(filename, 'r'). It is best practice to use the with statement as you never have to concern yourself with closing the files again.\n",
    "\n",
    "12. In the exercises, you’ll:\n",
    "In the following interactive coding sessions, you’ll figure out how to print files to console. You’ll also learn to print specific lines, which can be very useful for large files. Then we’ll be back to discuss flat files and then I'll show you how to use the Python package NumPy to make our job of importing flat files & numerical data a far easier beast to tame.\n",
    "\n",
    "13. Let's practice!\n",
    "Enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fbdca2",
   "metadata": {},
   "source": [
    "# Intro Video Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2baa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'huck_finn.txt'\n",
    "file = open(filename, mode='r') #'r' is to read, 'w' is to write\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3127a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER I.\n",
      "\n",
      "You donâ€™t know about me without you have read a book by the name of The Adventures of Tom Sawyer; but that ainâ€™t no matter. That book was made by Mr. Mark Twain, and he told the truth, mainly. There was things which he stretched, but mainly he told the truth. That is nothing. I never seen anybody but lied one time or another, without it was Aunt Polly, or the widow, or maybe Mary. Aunt Pollyâ€”Tomâ€™s Aunt Polly, she isâ€”and Mary, and the Widow Douglas is all told about in that book, which is mostly a true book, with some stretchers, as I said before.\n",
      "\n",
      "Now the way that the book winds up is this: Tom and me found the money that the robbers hid in the cave, and it made us rich. We got six thousand dollars apieceâ€”all gold. It was an awful sight of money when it was piled up. Well, Judge Thatcher he took it and put it out at interest, and it fetched us a dollar a day apiece all the year roundâ€”more than a body could tell what to do with. The Widow Douglas she took me for her son, and allowed she would sivilize me; but it was rough living in the house all the time, considering how dismal regular and decent the widow was in all her ways; and so when I couldnâ€™t stand it no longer I lit out. I got into my old rags and my sugar-hogshead again, and was free and satisfied. But Tom Sawyer he hunted me up and said he was going to start a band of robbers, and I might join if I would go back to the widow and be respectable. So I went back.\n",
      "\n",
      "The widow she cried over me, and called me a poor lost lamb, and she called me a lot of other names, too, but she never meant no harm by it. She put me in them new clothes again, and I couldnâ€™t do nothing but sweat and sweat, and feel all cramped up. Well, then, the old thing commenced again. The widow rung a bell for supper, and you had to come to time. When you got to the table you couldnâ€™t go right to eating, but you had to wait for the widow to tuck down her head and grumble a little over the victuals, though there warnâ€™t really anything the matter with them,â€”that is, nothing only everything was cooked by itself. In a barrel of odds and ends it is different; things get mixed up, and the juice kind of swaps around, and the things go better.\n",
      "\n",
      "After supper she got out her book and learned me about Moses and the Bulrushers, and I was in a sweat to find out all about him; but by and by she let it out that Moses had been dead a considerable long time; so then I didnâ€™t care no more about him, because I donâ€™t take no stock in dead people.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62e91537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER I.\n",
      "\n",
      "You donâ€™t know about me without you have read a book by the name of The Adventures of Tom Sawyer; but that ainâ€™t no matter. That book was made by Mr. Mark Twain, and he told the truth, mainly. There was things which he stretched, but mainly he told the truth. That is nothing. I never seen anybody but lied one time or another, without it was Aunt Polly, or the widow, or maybe Mary. Aunt Pollyâ€”Tomâ€™s Aunt Polly, she isâ€”and Mary, and the Widow Douglas is all told about in that book, which is mostly a true book, with some stretchers, as I said before.\n",
      "\n",
      "Now the way that the book winds up is this: Tom and me found the money that the robbers hid in the cave, and it made us rich. We got six thousand dollars apieceâ€”all gold. It was an awful sight of money when it was piled up. Well, Judge Thatcher he took it and put it out at interest, and it fetched us a dollar a day apiece all the year roundâ€”more than a body could tell what to do with. The Widow Douglas she took me for her son, and allowed she would sivilize me; but it was rough living in the house all the time, considering how dismal regular and decent the widow was in all her ways; and so when I couldnâ€™t stand it no longer I lit out. I got into my old rags and my sugar-hogshead again, and was free and satisfied. But Tom Sawyer he hunted me up and said he was going to start a band of robbers, and I might join if I would go back to the widow and be respectable. So I went back.\n",
      "\n",
      "The widow she cried over me, and called me a poor lost lamb, and she called me a lot of other names, too, but she never meant no harm by it. She put me in them new clothes again, and I couldnâ€™t do nothing but sweat and sweat, and feel all cramped up. Well, then, the old thing commenced again. The widow rung a bell for supper, and you had to come to time. When you got to the table you couldnâ€™t go right to eating, but you had to wait for the widow to tuck down her head and grumble a little over the victuals, though there warnâ€™t really anything the matter with them,â€”that is, nothing only everything was cooked by itself. In a barrel of odds and ends it is different; things get mixed up, and the juice kind of swaps around, and the things go better.\n",
      "\n",
      "After supper she got out her book and learned me about Moses and the Bulrushers, and I was in a sweat to find out all about him; but by and by she let it out that Moses had been dead a considerable long time; so then I didnâ€™t care no more about him, because I donâ€™t take no stock in dead people.\n"
     ]
    }
   ],
   "source": [
    "with open('huck_finn.txt','r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7d4774",
   "metadata": {},
   "source": [
    "# Importing entire text files\n",
    "In this exercise, you'll be working with the file moby_dick.txt. It is a text file that contains the opening sentences of Moby Dick, one of the great American novels! Here you'll get experience opening a text file, printing its contents to the shell and, finally, closing it.\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Open the file moby_dick.txt as read-only and store it in the variable file. Make sure to pass the filename enclosed in quotation marks ''.\n",
    "Print the contents of the file to the shell using the print() function. As Hugo showed in the video, you'll need to apply the method read() to the object file.\n",
    "Check whether the file is closed by executing print(file.closed).\n",
    "Close the file using the close() method.\n",
    "Check again that the file is closed as you did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "258a22a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call me Ishmael. \n",
      "Some years agoâ€”never mind how long preciselyâ€”having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world. \n",
      "It is a way I have of driving off the spleen and regulating the circulation. \n",
      "Whenever I find myself growing grim about the mouth; whenever it is a damp, drizzly November in my soul; whenever I find myself involuntarily pausing before coffin warehouses, and bringing up the rear of every funeral I meet; \n",
      "and especially whenever my hypos get such an upper hand of me, that it requires a strong moral principle to prevent me from deliberately stepping into the street, and methodically knocking peopleâ€™s hats offâ€”then, I account it \n",
      "high time to get to sea as soon as I can. This is my substitute for pistol and ball. With a philosophical flourish Cato throws himself upon his sword; I quietly take to the ship. There is nothing surprising in this. \n",
      "If they but knew it, almost all men in their degree, some time or other, cherish very nearly the same feelings towards the ocean with me.\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Open a file: file\n",
    "file = open('moby_dick.txt', 'r')\n",
    "\n",
    "# Print it\n",
    "print(file.read())\n",
    "\n",
    "# Check whether file is closed\n",
    "print(file.closed)\n",
    "\n",
    "# Close file\n",
    "file.close()\n",
    "\n",
    "# Check whether file is closed\n",
    "print(file.closed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad0af49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call me Ishmael. \n",
      "\n",
      "Some years agoâ€”never mind how long preciselyâ€”having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world. \n",
      "\n",
      "It is a way I have of driving off the spleen and regulating the circulation. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read & print the first 3 lines\n",
    "with open('moby_dick.txt') as file:\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n",
    "    print(file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f089bdf",
   "metadata": {},
   "source": [
    "# 1. The importance of flat files in data science\n",
    "Now you know how to import plain text files,\n",
    "\n",
    "2. Flat files\n",
    "we're going to look at flat files, such as 'titanic dot csv',\n",
    "\n",
    "3. Flat files\n",
    "in which each\n",
    "\n",
    "4. Flat files\n",
    "row is a unique passenger onboard and each\n",
    "\n",
    "5. Flat files\n",
    "column is a feature of attribute, such as gender, cabin and 'survived or not'. It is essential for any budding data scientist to know precisely what the term flat file means.\n",
    "\n",
    "6. Flat files\n",
    "Flat files are basic text files containing records, that is, table data, without structured relationships. This is in contrast to a relational database, for example, in which columns of distinct tables can be related. We'll get to these later. To be even more precise, flat files consist of records, where by a record we mean a row of fields or attributes, each of which contains at most one item of information. In the flat file 'titanic dot csv', each\n",
    "\n",
    "7. Flat files\n",
    "row or record is a unique passenger onboard and each column is a feature or attribute, such as\n",
    "\n",
    "8. Flat files\n",
    "name, gender and cabin.\n",
    "\n",
    "9. Header\n",
    "It is also essential to note that a flat file can have a header, such as in 'titanic dot csv', which is a\n",
    "\n",
    "10. Header\n",
    "row that occurs as the first row and describes the contents of the data columns or states what the corresponding attributes or features in each column are. It will be important to know whether or not your file has a header as it may alter your data import. The reason that flat files are so important in data science is that we data scientists really honestly like to think in records or rows of attributes.\n",
    "\n",
    "11. File extension\n",
    "Now you may have noticed that the file extension was dot csv. You may be wondering what this is? Well, CSV is an acronym for comma separated value and it means exactly what it says. The values in each row are separated by commas. Another common extension for a flat file is dot txt, which means a text file. Values in flat files can be separated by characters or sequences of characters other than commas, such as a tab, and the character or characters in question is called a delimiter.\n",
    "\n",
    "12. Tab-delimited file\n",
    "See here an example of a tab-delimited file. The data consists of the famous MNIST digit recognition images, where\n",
    "\n",
    "13. Tab-delimited file\n",
    "each row contains the pixel values of a given image. Note that all fields in the MNIST data are numeric, while the 'titanic dot csv' also contained strings.\n",
    "\n",
    "14. How do you import flat files?\n",
    "How do we import such files? If they consist entirely of numbers and we want to store them as a numpy array, we could use numpy. If, instead, we want to store the data in a dataframe, we could use pandas. Most of the time, you will use one of these options. In the rest of this Chapter, you'll learn how to import flat files that contain only numerical data, such as the MNIST data, and import flat files that contain both numerical data and strings, such as 'titanic dot csv'.\n",
    "\n",
    "15. Let's practice!\n",
    "But first, lets get you to do a couple of quick multiple choice questions to test your knowledge of flat files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e78e72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38aaf37",
   "metadata": {},
   "source": [
    "# 1. Importing flat files using NumPy\n",
    "Okay so you now know how to use Python’s built-in open function to open text files. What if you now want to import a flat file and assign it to a variable? If all the data are numerical, you can use the package numpy to import the data as a numpy array. Why would we want to do this?\n",
    "\n",
    "2. Why NumPy?\n",
    "First off, numpy arrays are the Python standard for storing numerical data. They are efficient, fast and clean.\n",
    "\n",
    "3. Why NumPy?\n",
    "Secondly, numpy arrays are often essential for other packages, such as scikit-learn, a popular Machine Learning package for Python. Numpy itself has a number of built-in functions that make it far easier and more efficient for us to import data as arrays. Enter the NumPy functions loadtxt and genfromtxt.\n",
    "\n",
    "4. Importing flat files using NumPy\n",
    "To use either of these we first need to import NumPy. We then call loadtxt and pass it the filename as the first argument, along with the delimiter as the 2nd argument. Note that the default delimiter is any white space so we’ll usually need to specify it explicitly.\n",
    "\n",
    "5. Customizing your NumPy import\n",
    "There are a number of additional arguments you may wish to specify. If, for example, your data consists of numerics and your header has strings in it, such as in the MNIST digits data, you will want to skip the first row by calling loadtxt with the argument skiprows equals 1; if you want only the 1st and 3rd columns of the data,\n",
    "\n",
    "6. Customizing your NumPy import\n",
    "you’ll want to set usecols equals the list containing ints 0 and 2.\n",
    "\n",
    "7. Customizing your NumPy import\n",
    "You can also import different datatypes into NumPy arrays: for example, setting the argument dtype equals 'str' will ensure that all entries are imported as strings. loadtxt is great for basic cases, but tends to break down when we have\n",
    "\n",
    "8. Mixed datatypes\n",
    "mixed datatypes, for example,\n",
    "\n",
    "1 Source: Kaggle\n",
    "9. Mixed datatypes\n",
    "columns consisting of floats AND columns consisting of strings, such as we saw in the Titanic dataset.\n",
    "\n",
    "1 Source: Kaggle\n",
    "10. Let's practice!\n",
    "Now it's your turn to have fun with loadtxt. You'll also gain hands-on experience with other functions that can handle mixed datatypes. In the next video we’ll see that, although NumPy arrays can handle data of mixed types, the natural place for such data really is the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eefaba",
   "metadata": {},
   "source": [
    "# Using NumPy to import flat files\n",
    "In this exercise, you're now going to load the MNIST digit recognition dataset using the numpy function loadtxt() and see just how easy it can be:\n",
    "\n",
    "The first argument will be the filename.\n",
    "The second will be the delimiter which, in this case, is a comma.\n",
    "You can find more information about the MNIST dataset here on the webpage of Yann LeCun, who is currently Director of AI Research at Facebook and Founding Director of the NYU Center for Data Science, among many other things.\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Fill in the arguments of np.loadtxt() by passing file and a comma ',' for the delimiter.\n",
    "Fill in the argument of print() to print the type of the object digits. Use the function type().\n",
    "Execute the rest of the code to visualize one of the rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c56c2511",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "digits.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d6ed6200235d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Load file as array: digits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdigits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'digits.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Print datatype of digits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1065\u001b[1;33m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1066\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    529\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: digits.csv not found."
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import numpy as np\n",
    "\n",
    "# Assign filename to variable: file\n",
    "file = 'digits.csv'\n",
    "\n",
    "# Load file as array: digits\n",
    "digits = np.loadtxt('digits.csv', delimiter=',')\n",
    "\n",
    "# Print datatype of digits\n",
    "print(type(digits))\n",
    "\n",
    "# Select and reshape a row\n",
    "im = digits[21, 1:]\n",
    "im_sq = np.reshape(im, (28, 28))\n",
    "\n",
    "# Plot reshaped data (matplotlib.pyplot already loaded as plt)\n",
    "plt.imshow(im_sq, cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3476cfe",
   "metadata": {},
   "source": [
    "# Customizing your NumPy import\n",
    "What if there are rows, such as a header, that you don't want to import? What if your file has a delimiter other than a comma? What if you only wish to import particular columns?\n",
    "\n",
    "There are a number of arguments that np.loadtxt() takes that you'll find useful:\n",
    "\n",
    "delimiter changes the delimiter that loadtxt() is expecting.\n",
    "You can use ',' for comma-delimited.\n",
    "You can use '\\t' for tab-delimited.\n",
    "skiprows allows you to specify how many rows (not indices) you wish to skip\n",
    "usecols takes a list of the indices of the columns you wish to keep.\n",
    "The file that you'll be importing, digits_header.txt, has a header and is tab-delimited.\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Complete the arguments of np.loadtxt(): the file you're importing is tab-delimited, you want to skip the first row and you only want to import the first and third columns.\n",
    "Complete the argument of the print() call in order to print the entire array that you just imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ade32336",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "digits_header.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-06319ff0604a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Load the data: data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Print data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1065\u001b[1;33m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1066\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    529\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: digits_header.txt not found."
     ]
    }
   ],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Assign the filename: file\n",
    "file = 'digits_header.txt'\n",
    "\n",
    "# Load the data: data\n",
    "data = np.loadtxt(file, delimiter='\\t', skiprows=1, usecols=[0,2])\n",
    "\n",
    "# Print data\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f105b18",
   "metadata": {},
   "source": [
    "Importing different datatypes\n",
    "The file seaslug.txt\n",
    "\n",
    "has a text header, consisting of strings\n",
    "is tab-delimited.\n",
    "These data consists of percentage of sea slug larvae that had metamorphosed in a given time period. Read more here.\n",
    "\n",
    "Due to the header, if you tried to import it as-is using np.loadtxt(), Python would throw you a ValueError and tell you that it could not convert string to float. There are two ways to deal with this: firstly, you can set the data type argument dtype equal to str (for string).\n",
    "\n",
    "Alternatively, you can skip the first row as we have seen before, using the skiprows argument.\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Complete the first call to np.loadtxt() by passing file as the first argument.\n",
    "Execute print(data[0]) to print the first element of data.\n",
    "Complete the second call to np.loadtxt(). The file you're importing is tab-delimited, the datatype is float, and you want to skip the first row.\n",
    "Print the 10th element of data_float by completing the print() command. Be guided by the previous print() call.\n",
    "Execute the rest of the code to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30a14302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time' 'Percent']\n",
      "[0.    0.533]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign filename: file\n",
    "file = 'seaslug.txt'\n",
    "\n",
    "# Import file: data\n",
    "data = np.loadtxt(file, delimiter='\\t', dtype=str)\n",
    "\n",
    "# Print the first element of data\n",
    "print(data[0])\n",
    "\n",
    "# Import data as floats and skip the first row: data_float\n",
    "data_float = np.loadtxt('seaslug.txt', delimiter='\\t', dtype=float, skiprows=1)\n",
    "\n",
    "# Print the 10th element of data_float\n",
    "print(data_float[10])\n",
    "\n",
    "# Plot a scatterplot of the data\n",
    "plt.scatter(data_float[:, 0], data_float[:, 1])\n",
    "plt.xlabel('time (min.)')\n",
    "plt.ylabel('percentage of larvae')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccba2cab",
   "metadata": {},
   "source": [
    "# Working with mixed datatypes (1)\n",
    "Much of the time you will need to import datasets which have different datatypes in different columns; one column may contain strings and another floats, for example. The function np.loadtxt() will freak at this. There is another function, np.genfromtxt(), which can handle such structures. If we pass dtype=None to it, it will figure out what types each column should be.\n",
    "\n",
    "Import 'titanic.csv' using the function np.genfromtxt() as follows:\n",
    "\n",
    "data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)\n",
    "Here, the first argument is the filename, the second specifies the delimiter , and the third argument names tells us there is a header. Because the data are of different types, data is an object called a structured array. Because numpy arrays have to contain elements that are all the same type, the structured array solves this by being a 1D array, where each element of the array is a row of the flat file imported. You can test this by checking out the array's shape in the shell by executing np.shape(data).\n",
    "\n",
    "Accessing rows and columns of structured arrays is super-intuitive: to get the ith row, merely execute data[i] and to get the column with name 'Fare', execute data['Fare'].\n",
    "\n",
    "After importing the Titanic data as a structured array (as per the instructions above), print the entire column with the name Survived to the shell. What are the last 4 values of this column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8844d7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-dfc98d6d9304>:1: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  data = np.genfromtxt('titanic_sub.csv', delimiter=',', names=True, dtype=None)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('titanic_sub.csv', delimiter=',', names=True, dtype=None)\n",
    "print(data['Survived'][-4:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2bb64",
   "metadata": {},
   "source": [
    "# Working with mixed datatypes (2)\n",
    "You have just used np.genfromtxt() to import data containing mixed datatypes. There is also another function np.recfromcsv() that behaves similarly to np.genfromtxt(), except that its default dtype is None. In this exercise, you'll practice using this to achieve the same result.\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Import titanic.csv using the function np.recfromcsv() and assign it to the variable, d. You'll only need to pass file to it because it has the defaults delimiter=',' and names=True in addition to dtype=None!\n",
    "Run the remaining code to print the first three entries of the resulting array d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0acc4470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0, 3, b'male', 22., 1, 0, b'A/5 21171',  7.25  , b'', b'S')\n",
      " (2, 1, 1, b'female', 38., 1, 0, b'PC 17599', 71.2833, b'C85', b'C')\n",
      " (3, 1, 3, b'female', 26., 0, 0, b'STON/O2. 3101282',  7.925 , b'', b'S')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derek\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:2405: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  output = genfromtxt(fname, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Assign the filename: file\n",
    "file = 'titanic_sub.csv'\n",
    "\n",
    "# Import file using np.recfromcsv: d\n",
    "d = np.recfromcsv(file)\n",
    "\n",
    "# Print out first three entries of d\n",
    "print(d[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2860e1",
   "metadata": {},
   "source": [
    "# 1. Importing flat files using pandas\n",
    "Congrats! You're now able to import a bunch of different types of flat files into Python as NumPy arrays. Although arrays are incredibly powerful and serve a number of essential purposes, they cannot fulfill one of the most basic needs of a Data Scientist:\n",
    "\n",
    "2. What a data scientist needs\n",
    "to have \"[two]-dimensional labeled data structure[s] with columns of potentially different types\" that you can easily perform a plethora of Data Sciencey type things on: manipulate, slice, reshaped, groupby, join, merge, perform statistics in a missing-value-friendly manner, deal with times series. The need for such a data structure, among other issues,\n",
    "\n",
    "3. Pandas and the DataFrame\n",
    "prompted Wes McKinney to develop the\n",
    "\n",
    "4. Pandas and the DataFrame\n",
    "pandas library for Python. Nothing speaks to the project of pandas more than the documentation itself:\n",
    "\n",
    "5. Pandas and the DataFrame\n",
    "\"Python has long been great for data munging and preparation, but less so for data analysis and modeling. pandas helps fill this gap, enabling you to carry out your entire data analysis workflow in Python without having to switch to a more domain specific language like R.\" The data structure most relevant to the data manipulation and analysis workflow that pandas offers is the dataframe and it is the Pythonic analogue of R’s dataframe.\n",
    "\n",
    "6. Pandas and the DataFrame\n",
    "As Hadley Wickham tweeted, \"A matrix has rows and columns. A data frame has observations and variables.\"\n",
    "\n",
    "7. Manipulating pandas DataFrames\n",
    "Manipulating dataframes in pandas can be useful in all steps of the data scientific method, from exploratory data analysis to data wrangling, preprocessing, building models and visualization. Here we will see its great utility in importing flat files, even merely in the way that it deals with missing data, comments along with the many other issues that plague working data scientists. For all of these reasons, it is now standard and best practice in Data Science to use pandas to import flat files as dataframes. Later in this course, we’ll see how many other types of data, whether they’re stored in relational databases, hdf5, MATLAB or excel files, can easily be imported as dataframes.\n",
    "\n",
    "8. Importing using pandas\n",
    "To use pandas, you first need to import it. Then, if we wish to import a CSV in the most basic case all we need to do is to call the function read_csv and supply it with a single argument, the name of the file. Having assigned the dataframe to the variable data, we can check the first 5 rows of the dataframe, including the header, with the command 'data dot head'. We can also easily convert to the dataframe to a numpy array by calling the dataframe attribute values. Now it's your turn to play around importing flat files using Python.\n",
    "\n",
    "9. You’ll experience:\n",
    "You'll get experience importing a flat file that is straightforward and you'll also get experience importing a flat file that has a few issues, such as containing comments and strings that should be interpreted as missing values.\n",
    "\n",
    "10. Let's practice!\n",
    "Have fun importing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6463cf",
   "metadata": {},
   "source": [
    "# Using pandas to import flat files as DataFrames (1)\n",
    "In the last exercise, you were able to import flat files containing columns with different datatypes as numpy arrays. However, the DataFrame object in pandas is a more appropriate structure in which to store such data and, thankfully, we can easily import files of mixed data types as DataFrames using the pandas functions read_csv() and read_table().\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Import the pandas package using the alias pd.\n",
    "Read titanic.csv into a DataFrame called df. The file name is already stored in the file object.\n",
    "In a print() call, view the head of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4247f9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n",
      "0            1         0       3    male  22.0      1      0   \n",
      "1            2         1       1  female  38.0      1      0   \n",
      "2            3         1       3  female  26.0      0      0   \n",
      "3            4         1       1  female  35.0      1      0   \n",
      "4            5         0       3    male  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare Cabin Embarked  \n",
      "0         A/5 21171   7.2500   NaN        S  \n",
      "1          PC 17599  71.2833   C85        C  \n",
      "2  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3            113803  53.1000  C123        S  \n",
      "4            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Assign the filename: file\n",
    "file = 'titanic_sub.csv'\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# View the head of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b3c1d0",
   "metadata": {},
   "source": [
    "# Using pandas to import flat files as DataFrames (2)\n",
    "In the last exercise, you were able to import flat files into a pandas DataFrame. As a bonus, it is then straightforward to retrieve the corresponding numpy array using the attribute values. You'll now have a chance to do this using the MNIST dataset, which is available as digits.csv.\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Import the first 5 rows of the file into a DataFrame using the function pd.read_csv() and assign the result to data. You'll need to use the arguments nrows and header (there is no header in this file).\n",
    "Build a numpy array from the resulting DataFrame in data and assign to data_array.\n",
    "Execute print(type(data_array)) to print the datatype of data_array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f89742c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'digits.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-4e84b27da9c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Read the first 5 rows of the file into a DataFrame: data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Build a numpy array from the DataFrame: data_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'digits.csv'"
     ]
    }
   ],
   "source": [
    "# Assign the filename: file\n",
    "file = 'digits.csv'\n",
    "\n",
    "# Read the first 5 rows of the file into a DataFrame: data\n",
    "data = pd.read_csv(file, nrows=5, header=None)\n",
    "\n",
    "# Build a numpy array from the DataFrame: data_array\n",
    "data_array = data.values\n",
    "\n",
    "# Print the datatype of data_array to the shell\n",
    "print(type(data_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cc52bb",
   "metadata": {},
   "source": [
    "# Customizing your pandas import\n",
    "The pandas package is also great at dealing with many of the issues you will encounter when importing data as a data scientist, such as comments occurring in flat files, empty lines and missing values. Note that missing values are also commonly referred to as NA or NaN. To wrap up this chapter, you're now going to import a slightly corrupted copy of the Titanic dataset titanic_corrupt.txt, which\n",
    "\n",
    "contains comments after the character '#'\n",
    "is tab-delimited.\n",
    "Instructions\n",
    "100 XP\n",
    "Complete the sep (the pandas version of delim), comment and na_values arguments of pd.read_csv(). comment takes characters that comments occur after in the file, which in this case is '#'. na_values takes a list of strings to recognize as NA/NaN, in this case the string 'Nothing'.\n",
    "Execute the rest of the code to print the head of the resulting DataFrame and plot the histogram of the 'Age' of passengers aboard the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6ed9c48",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'titanic_corrupt.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-97a2bf343b4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Import file: data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'#'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Nothing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Print the head of the DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanic_corrupt.txt'"
     ]
    }
   ],
   "source": [
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assign filename: file\n",
    "file = 'titanic_corrupt.txt'\n",
    "\n",
    "# Import file: data\n",
    "data = pd.read_csv(file, sep='\\t', comment='#', na_values='Nothing')\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(data.head())\n",
    "\n",
    "# Plot 'Age' variable in a histogram\n",
    "pd.DataFrame.hist(data[['Age']])\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dbb6ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n",
      "0            1         0       3    male  22.0      1      0   \n",
      "1            2         1       1  female  38.0      1      0   \n",
      "2            3         1       3  female  26.0      0      0   \n",
      "3            4         1       1  female  35.0      1      0   \n",
      "4            5         0       3    male  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare Cabin Embarked  \n",
      "0         A/5 21171   7.2500   NaN        S  \n",
      "1          PC 17599  71.2833   C85        C  \n",
      "2  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3            113803  53.1000  C123        S  \n",
      "4            373450   8.0500   NaN        S  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assign filename: file\n",
    "file = 'titanic_sub.csv'\n",
    "\n",
    "# Import file: data\n",
    "data = pd.read_csv(file)\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(data.head())\n",
    "\n",
    "# Plot 'Age' variable in a histogram\n",
    "pd.DataFrame.hist(data[['Age']])\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe7064",
   "metadata": {},
   "source": [
    "# 1. Final thoughts on data import\n",
    "We have seen a number of ways to read, print and import flat files. As a data scientist, you will most often wish to use pandas, however it was important to check out all the possible ways to import because you never know when they will be useful.\n",
    "\n",
    "2. Next chapters:\n",
    "In the next chapter, we'll see just how useful pandas can be when attempting to import a variety of other file types, such as Excel spreadsheets, along with native SAS & Stata files. It is also important to remember that, due to the active development community in open source softwares, there is constant activity in file formats and ways to import data: for example, on March 29, 2016, Wes McKinney, the creator of pandas, and Hadley Wickham, of R development fame, announced a new and fast on-disk format for dataframes for R and Python, called feather . As dataframes are one the most important data structures for data scientists, let's definitely keep our eyes on feather. After learning to import many other file types in the next chapter, you'll learn how to interact with relational databases in Python.\n",
    "\n",
    "3. Next course:\n",
    "Then, in the sequel to this course, you'll learn how to tear all types of data down from the web and how to interact with APIs to fulfil your big data fix. These are all essential techniques for the modern day Data Scientist to master, and the upcoming Chapters will place you in good stead to becoming\n",
    "\n",
    "4. Let's practice!\n",
    "an Importing Data ninja Pythonista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45030d45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
